## Term Project Assignment 2 - 10 pnts

In this assignment you will develop the main goal and objectives of your term project and explore, evaluate, and select data sources. A key component of this process is formulating a research question or develop a workflow. The workflow for this assignment will help you refine your question and identify the datasets needed to address it. 

### Brainstorming

**Q1. What is the primary research question/objective for your term project? (1-2 sentences)(1 pt)** <br>
Think of this as your first approach to developing a research question. It should reflect a clear purpose and be specific enough to guide your initial search for data, but it likely will evolve throughout this assignment. That is okay, even expected. You will be asked for a refined response at the end of the assignment.<br>
Consider: <br>
- The problem or issue you want to address  <br>
- What specific phenomenon within that issue are you interested in understanding  <br>
- What measurable or observable outcomes do you want to analyze.  <br>
For example, instead of 'how does climate change affect forests?', you might consider 'How has seasonal precipitation variability impacted the timing of peak NDVI in the Pacific Northwest from 2000 to 2020.' Note that this question is specific enough to guide your search for the necessary data, such as precipitation records and NDVI time series. <br>
ANSWER:


**Q2. What are 2-3 types of data your research question requires? Address each sub-question (2 pts)**
ANSWER:
1) For this project the variables and indicators we are looking for is salmon return data (specifically from streams with USGS gages), stream discharge data, precipitation data, and air temperature data.

2) The data should all be in the form of time-series data, however, we will likely use the map function previously used in labs to display where the stream gages we are using information from are located. 

3) The salmon return data will be survey type data from the stateofsalmon.wa.gov website. The stream discharge data will come from three different USGS gages. The precipitation and air temperature data will come from daymet data.

4) As salmon have a 3-5 year life cycle depending on the species a longer temporal length would be best, ideally spanning 20+ years so that patterns across multiple generations can be examined. The resolution of the data will depend on the variable. Salmon return data are reported as annual totals, so this data will be represented as a single value each year. However, having daily data for stream flow, precipitation, and air temperature would allow for examination of annual patterns and help to determine if there is a correlation between changes in these factors and salmon returns. Therefore these three variables will be examined on a daily basis. 


### Data exploration and selection

**Q3. Explore your data, this part requires 2 answers (3 pnts total)**
```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Install needed packages

```{r}
library(dataRetrieval)
library(tidyverse)
library(dplyr)
library(patchwork)
library(zoo)
library(daymetr)
library(leaflet)
library(fs)
library(ggpubr)
```

**Write a brief summary (3-4 sentences) describing your data.** 

Generate plots:
Create at least one plot that summarizes the data and describe it's use to you. Are there gaps in the data? Does the data cover the time or space you are interested in? Are there significant outliers that need consideration? 

```{r}

```

Generate a histogram or density plot of at least one variable in your dataset. The script here will help start a density plot showing multiple variables. You may adapt or change this as needed. 

```{r}
#plottable_vars <- dfname %>%
#  dplyr::select(variable1, variable2,...)
                
#long <- plottable_vars %>%
#  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Value")

# Plot density plots for each variable
#ggplot(long, aes(x = Value, fill = Variable)) +
#  geom_density(alpha = 0.5) +  # Add transparency for overlapping densities
# facet_wrap(~ Variable, scales = "free", ncol = 2) +  # Create separate panels per variable
#  theme_minimal() +
#  labs(title = "Density Plots for Variables",
 #      x = "Value", y = "Density")
```

**What does the above plot tell you about the distribution of your data? Is it as expected? Why do we need to consider the distribution of data when deciding on analysis methods?**



**Q4. Putting it all together (3 pts)**
Create a table in R and export it as a .csv file to submit with this assignment .rmd.

In this table, include all datasets (up to now) that you will use for your term project. The script below specifies all of the sections required in this table, though you will need to change names and information accordingly in c(). Also, not everything in this table may pertain to you and your project. So we can change things accordingly. 

```{r, message=FALSE}
# Load necessary library
library(dplyr)

# Create a data frame
data_table <- data.frame(
  Dataset_Name = c("Dataset1", 'Dataset2'),
  Data_Source = c('NOAA', 'NRCS'), #Agency or institution name
  Data_Type = c("Climate", "Hydrology"), # what kind of data is it?
  Source_Link = c("https://www.link1/", 
                  "https://link2/"), # We will used these to access the sources. This is if you are getting data from the web. 
  Key_variables = c('precipitation', 'soil_conductivity'), 
  Temporal_range = c('2020-2021', '1979-today'),
  Spatial_Coverage = c('Montana', 'Juneau_AK'),
  Data_Quality = c("High", "Moderate"), # An example of high quality might be a dataset that has already been cleaned by an agency is not missing data in the period or space of interest. 
  Data_Quality_notes = c('QCd with no missing data', 'some unexpected values'),
  Feasibility = c("High", "Medium"), # How useable is this to you? Do you need help figuring out how to download it? Is there an R package that you need to learn to access the data?
  Feasibility_notes = c('note1', 'note2'),
  variable_type = c('explanatory', 'response')
)

# Display the table
print(data_table)

# Export the data table as a .csv to a file path of your choice:
#exportpath <- file.path(getwd(), somefolder, term_assign_table.csv) #replace somefolde with an actual folder name that exists in your local environment
#write.csv(data_able, exportpath, row.names=FALSE)
```

Once this is exported, you can format if desired for readibility and submit the .csv with a completed .rmd. 

**Q5. What is your updated term project question/objective? How, specifically, will the data sources listed above help you to answer that question? (1 pt)**
