---
output: html_document
editor_options: 
  chunk_output_type: console
chunk_output_type: console
---
Mackenzie Adams and Henry Scott

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

Install and load needed packages

```{r}
library(dataRetrieval)
library(tidyverse)
library(dplyr)
library(patchwork)
library(zoo)
library(daymetr) 
library(leaflet) 
library(fs)
library(ggpubr) # for adding R and P vals to graphs
library(DescTools) # for doing Mode statistical calc
library(rstatix)
```

```{r}
# USGS GAGE INFO/DATA 

# This efficiently automates the process of getting all the stream data desired into one df.

gage_ids <- 
  tribble(
    ~site_name,        ~site_no,
    "Dungeness_River",  "12048000",
    "Elwha_River",      "12045500",
    "Skokomish_River",  "12061500")

# set all the parameters
start <- date("1982-10-01")
end <- date("2023-9-30")
para <-c("00060", "00065")

# if sites in gage_ids are changed, uncomment the code below and run it once. This stores the data locally and eventually in the repo if its pushed. This is mostly to be polite to the USGS hosting service.

# NWIS_data <- readNWISdv(gage_ids$site_no, para, start, end)
# saveRDS(NWIS_data, "NWIS_data.rdata")
# 
# NWIS_meta <- readNWISsite(gage_ids$site_no)
# saveRDS(NWIS_meta, "NWIS_meta.rdata")

gage_ids <- 
  readRDS("NWIS_meta.rdata") %>% 
  select(site_no,
         dec_lat_va, 
         dec_long_va) %>%
  inner_join(gage_ids, .)

gage_data <-
  readRDS("NWIS_data.rdata") %>%
  inner_join(gage_ids, .) %>%
  renameNWISColumns() %>%
  drop_na(Flow) %>%
  mutate(water_year = calcWaterYear(Date)) %>%
  group_by(site_name, site_no)


# Shows all unique grouped elements in gage_data. Verifies that all the desired gages were selected and are in the data frame.

summarize(gage_data)

```


```{r}
# WEATHER DATA ACQUISITION: This code retrieves the desired precipitation and temperature data.

# write_csv(x = select(gage_ids, -"site_no"), file = "gage_ids.csv")
# 
# daymet_all <- download_daymet_batch(file_location = "./gage_ids.csv", start = year(start), end = year(end), internal = T, simplify = F)
# saveRDS(daymet_all, "DAYMET_all.rdata")


# Downloading data works. Now to append it...

daymet_reorg <-
  function(f) {
    bind_cols(data = f$data, site = f$site, .name_repair = "unique")
  } 

gage_data_all <- 
  lapply(readRDS("./DAYMET_all.rdata"), daymet_reorg) %>%
  bind_rows() %>%
  rename(doy = yday, 
         ann = year,
         prcp_daily_mm = prcp..mm.day.,
         t_max_C = tmax..deg.c.,
         t_min_C = tmin..deg.c.) %>%
  mutate(
    Date = make_datetime(year = ann, day = doy),
    t_avg_C = (t_max_C + t_min_C)/2) %>%
  select(site,
         Date,
         prcp_daily_mm,
         t_max_C,
         t_min_C,
         t_avg_C,
         ann
  ) %>%
  left_join(ungroup(gage_data), ., join_by(site_name == site, Date == Date)) %>%
  drop_na(t_min_C)

#Now the discharge, precipitation, and temperature data is all in one data frame.
```


```{r}
# ADD FISH DATA: This code reads in csv files containing salmon return data downloaded for the particular rivers of interest from the stateofsalmon.wa.gov site.

fish_files <-
  dir_ls("./Salmon_Data/")


# creates a df of fish data. Originally, the code 1 chunk below this did this within its own workflow but I made it a seperate df bc i need it somewhere else, not attached to climate data
fish_data <-
  fish_files %>%
  lapply(read_csv) %>%
  bind_rows() %>%
  filter(data_type == "TSAEJ") %>%
  mutate(site_name = paste0(str_extract(population_name, "^\\w+"), "_River"), .before = "stock_number", year = year + 1) %>% 
  select(abundance_qty,
         year,
         site_name) %>%
  drop_na(abundance_qty)

gage_fish_all <-
  fish_files %>%
  lapply(read_csv) %>%
  bind_rows() %>%
  filter(data_type == "TSAEJ") %>%
  mutate(site_name = paste0(str_extract(population_name, "^\\w+"), "_River"), .before = "stock_number") %>% 
  select(abundance_qty,
         year,
         site_name) %>%
  drop_na(abundance_qty) %>%
  left_join(gage_data_all,., by = c(
    "water_year" = "year",
    "site_name" = "site_name"
  )
  )

# Make an offset df so that returns line up with the climate year they spawned in
gage_fish_lead <-
  gage_fish_all %>%
  group_by(site_name) %>% 
  mutate(abundance_lead = lead(abundance_qty, 365*4),
         Date_lead = Date + years(4),
         ann_lead = year(Date_lead)
         )
```


```{r}
#Mackenzie's attempt to correctly offset the data: this is closer than what we have but still not quite right

gage_fish_lead_2 <- gage_fish_all %>%
  mutate(Date = as.Date(Date))
  

env_data <- gage_fish_all %>%
 filter(year(Date) >= 1982 & year(Date) <= 2023) %>%
 select(site_name, Date, prcp_daily_mm, Flow, t_max_C, t_min_C, t_avg_C)

env_data <- env_data %>% 
  mutate(Date = Date + years (4))

abundance_data <- gage_data_all %>%
  filter(year(Date) >= 1986 & year(Date) <= 2023) %>%
  select(site_name, Date) 


aligned_data <- 
  abundance_data %>%
  left_join(env_data, by = c("site_name", "Date")) %>%
  addWaterYear() %>%
  left_join(., fish_data, by = c(
    "site_name" = "site_name",
    "waterYear" = "year")) %>%
  mutate(abundance_qty = abundance_qty)

```


```{r}
#This code produces a figure that shows years on the x axis and discharge on the y-axis for the three rivers of interest. The Dungeness River produces substantially less discharge compared to the Elwha and the Skokomish, therefore we set the boundaries for all three to be "free" so that patterns in discharge can more easily be examined and the data fills up the whole graph area.

q_gg <-
  gage_fish_all %>%
  ggplot(aes(x = Date, y = Flow, color = site_name)) +
  geom_line() + 
  theme_minimal() +
  facet_wrap(~ gsub("_", " ", site_name), nrow = 3, scales = "free") +
  labs( x = "Year", y = "Discharge (cfs)", color = "Gage") +
  theme(strip.text = element_text(size = 12), 
        axis.title.x = element_text(size = 14), 
        axis.title.y = element_text(size = 14), 
        legend.position = "none", )
```


```{r}
#This code generates a plot with year on the x-axis and precipitation(mm) on the y-axis for the areas where the three streams of interest are located.

prcp_gg <-
  gage_fish_all %>%
  ggplot(aes(x = Date, y = prcp_daily_mm, color = site_name)) +
  geom_line() + 
  theme_minimal() +
  facet_wrap(~ gsub("_", " ", site_name), nrow = 3, scales = "free") +
  labs( x = "Year", y = "Precipitation (mm)", color = "Gage") +
  theme(strip.text = element_text(size = 12), 
        axis.title.x = element_text(size = 14), 
        axis.title.y = element_text(size = 14), 
        legend.position = "none",)

```


```{r}
#This code generates a plot with year on the x-axis and average temperature(C) on the y-axis for the areas where the three streams of interest are located.

temp_gg <-
  gage_fish_all %>%
  ggplot(aes(x = Date, y = t_avg_C, color = site_name)) +
  geom_line() + 
  theme_minimal() +
  facet_wrap(~ gsub("_", " ", site_name), nrow = 3, scales = "free") +
  labs( x = "Year", y = "Temperature (C))", color = "Gage") +
  theme(strip.text = element_text(size = 12), 
        axis.title.x = element_text(size = 14), 
        axis.title.y = element_text(size = 14), 
        legend.position = "none",)
```


```{r}
#This code places the three above graphs side by side so that trends between the three rivers can easily be examined.

q_gg + prcp_gg + temp_gg

q_gg +prcp_gg 

prcp_gg + temp_gg

q_gg + temp_gg
```

```{r}
# lead the data so climate matches with returns, and some basic stats

gage_fish_lead %>%
  group_by(site_name, ann) %>%
  reframe(abd_qty_lead = Mode(abundance_lead), Flow = mean(Flow))  %>%
  ggplot(aes(x = abd_qty_lead, y = Flow, color = site_name)) +
  geom_point() +
  geom_smooth(method = "lm")


fish_aov <- gage_fish_lead %>% 
  anova_test(abundance_lead ~ Flow*prcp_daily_mm*t_avg_C)



gage_fish_lead %>%
  ggplot(aes(x = abundance_lead, y = Flow, color = site_name)) +
  geom_line() + geom_point()

```


```{r}

# Calculate the average and std dev of returns for each stream

abundance_stats <- 
  gage_fish_lead %>%
  ungroup() %>%
  summarise(return_avg = round(mean(abundance_lead, na.rm = T)), 
            return_sd = round(sd(abundance_lead, na.rm = T)), 
            .by = site_name)


# Creating a chart with annual return as a single point while still keeping annual data for everything   else

annual_salmon_returns <-
  gage_fish_lead %>%
  group_by(site_name, ann) %>%
  reframe(
    abundance_lead = Mode(abundance_lead, na.rm = TRUE), 
    ann = make_date(
      year = Mode(ann_lead), 
      month = 10, 
      day = 1),
    high_flow = max(Flow)
  ) %>% 
  left_join(abundance_stats, by = "site_name") %>%
  mutate(outlier = (abundance_lead > return_avg + return_sd | abundance_lead < return_avg - return_sd)) # checks if a given year is outside of 1 sd

DischargeandReturns <-
  gage_fish_lead %>%
  filter(Date_lead < "2023-10-01") %>%
  ggplot(aes(x = Date_lead, y = Flow, color = site_name)) +
  geom_line() +
  facet_wrap(facets = "site_name", 
             nrow = 3, 
             scales = "free") +
  geom_point(data = annual_salmon_returns, 
             aes(x = as.POSIXct(ann), 
                 y = abundance_lead), 
             color = "black", 
             size = .75) 


```



```{r}
#Line graphs showing how salmon populations have changed in the three rivers of interest over time. The returns are adjusted so the patterns align with the year the juveniles spent in the river. Therefore climate data is all shifted up backwards by four years.


annual_salmon_returns <- annual_salmon_returns %>%
mutate(site_name = recode(site_name,
"Elwha_River" = "Elwha River",
"Dungeness_River" = "Dungeness River",
"Skokomish_River" = "Skokomish River"))


#Returns over time of all three rivers on one graph.
annual_salmon_returns %>%
ggplot(aes(x = ann, y = abundance_lead, color = site_name)) +
geom_line() +
geom_point() + 
theme_classic() +
labs(
title = "Salmon Abundance Over Time",
color = "Site",
y = "Salmon Return Abundance",
x = "Year")

#Returns in each seperate river on seperate graphs stacked together.
annual_salmon_returns %>%
ggplot(aes(x = ann, y = abundance_lead, color = site_name)) +
geom_line() +
geom_point() +
theme_classic() +
labs(title = "Salmon Abundance Over Time",
color = "Site",
y = "Salmon Return Abundance",
x = "Year") +
facet_wrap(~ site_name, scales = "free_y", ncol = 1)


```

```{r}



```







```{r}
# Quickie model

t_mod <- 
  lm(formula = abundance_lead ~ , 
     data = annual_salmon_returns)

summary(t_mod)$coefficient

gage_fish_lead %>%
  # group_by(site_name, ann) %>%
  ggplot(aes(x = abundance_lead, y = Flow, color = site_name)) +
  geom_point()

```

```{r}
# preliminary example of data surrounding a high returns year

gage_fish_lead %>%
  filter(site_name == "Dungeness_River", Date_lead >= "2006-08-01" & Date_lead < "2007-06-01") %>%
  ggplot(aes(x = Date_lead, y = Flow)) +
  geom_line(color = "blue")
  
```

```{r}
# plot all of the different salmon returns 
annual_salmon_returns %>%
  ggplot(aes(x = ann, y = abundance_lead, color = site_name)) +
  geom_line() +
  facet_wrap(~ site_name, nrow = 3, scale = "free")


# Create a function and a loop that creates a ggplot object for when abundance is outside of sd
outlier_plotter <-
  function (f) {
    if (f$outlier == TRUE) {
      print("she works")
    }else {
      print("she dont work")
    }
  }


annual_salmon_returns %>%
  filter(site_name == "Dungeness_River") %>%
  ggplot(aes(x = ann, y = abundance_lead, color = site_name)) +
  geom_line() +
  geom_point() 

Dungeness_data <-
  gage_fish_lead %>%
  filter(site_name == "Dungeness_River")


# uses some temp columns to create filtered data. 
# filtered dates are based on arbitrarily generated Julian days, so changing the range first requires figuring out the corresponding Julian days.
#this one works but only on Dungeness
dungeness_julian <- 
  Dungeness_data %>%
  filter(ann_lead != 1986, ann_lead != 2027) %>%   #remove these rows bc theyre less than 365 days and that breaks things
  group_by(ann_lead) %>%
  mutate(fake_dates = seq(ymd('1970-01-01'),
                          ymd('1970-12-31'), 
                          by = '1 day'),
         fake_julian = julian(fake_dates, origin = as.Date("1970-01-01"))
  ) %>%
  filter(!(between(fake_julian, 151, 211))) %>%
  bind_rows(                                    #re-add the eariler filtered rows 
    (filter(
      Dungeness_data, year(Date_lead) < 1987)
    ),
    .) %>%
  bind_rows(
    (filter(
      Dungeness_data, year(Date_lead) > 2026)
    ),
    .) %>%
  arrange(Date_lead)


# attempting to do it to all sites
gage_fish_lead_filt <-
  gage_fish_lead %>%
  group_by(site_name) %>%
  filter(ann_lead != 1986, ann_lead != 2027) %>%   #remove these rows bc they're less than 365 days and that breaks things
  group_by(ann_lead) %>%
  mutate(fake_dates = seq(ymd('1970-01-01'),
                          ymd('1970-12-31'), 
                          by = '1 day'),
         fake_julian = julian(fake_dates, origin = as.Date("1970-01-01"))
  ) %>%
  filter(!(between(fake_julian, 151, 211))) %>%
  bind_rows(                                    #re-add the earlier filtered rows 
    (filter(
      gage_fish_lead, year(Date_lead) < 1987)
    ),
    .) %>%
  bind_rows(
    (filter(
      gage_fish_lead, year(Date_lead) > 2026)
    ),
    .) %>%
  arrange(Date_lead)


# create it as a function and lapply it?

migration_filter <-
  function(f) {
    f %>%
      filter(ann_lead != 1986, ann_lead != 2027) %>%   #remove these rows bc theyre less than 365 days and that breaks things
      group_by(ann_lead) %>%
      mutate(fake_dates = seq(ymd('1970-01-01'),
                              ymd('1970-12-31'), 
                              by = '1 day'),
             fake_julian = julian(fake_dates, origin = as.Date("1970-01-01"))
      ) %>%
      filter(!(between(fake_julian, 151, 211))) %>%
      bind_rows(                                    #re-add the eariler filtered rows 
        (filter(
          f, 
          year(Date_lead) < 1987)),
        .) %>%
      bind_rows(
        filter(
          f, 
          between(Date_lead, ymd("2027-01-01"), ymd("2027-05-31")) |
          ymd(Date_lead) > ymd("2027-07-31")),
        .) %>%
      arrange(Date_lead)
  }

gage_fish_lead %>%
  filter(site_name == "Skokomish_River") %>%
  migration_filter() %>%
  view()

gage_fish_lead %>%
  group_by(site_name) %>%
  group_map(~ migration_filter(.x))


where_fucked <-
  function(g) {
    g %>%
      group_by(site_no) %>%
      summarize(length = length(Date),
                sum_na = sum(is.na(Flow))
      )
  }

piss <-
  readRDS("./NWIS_data.rdata") %>%
  renameNWISColumns() %>%
  view()

where_fucked(piss)

where_fucked(gage_fish_lead)



```



